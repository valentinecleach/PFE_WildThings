---
title: "Wolverine_Explanations"
output: html_document
---

We have 4 different files to run the model on the Wolverine:
1 main script to run the model,
2 INPUTChain1 (One female Wolverine, the other Wolverine)
2 files of functions: dbin_LESSCachedAllSparseBear_v2.R, pointProcess.R

Model Code
```{BUGS}
{
    # Priors
    dispSigma ~ dunif(0, 10)
    betaDens ~ dnorm(0, 0.01)
    
    # numHabWindows : number of habitat-model observation windows
    mu[1:numHabWindows] <- exp(betaDens * denCounts[1:numHabWindows, 1] )
    
    # Initial activity center (t = 1)
    for (i in 1:n.individuals) {
        sxy[i, 1:2, 1] ~ dbinomPPSingle( # Function defined in pointProcess 2.3
          lowerHabCoords[1:numHabWindows, 1:2],
          upperHabCoords[1:numHabWindows, 1:2], 
          mu[1:numHabWindows], 
          1, 
          numHabWindows)
    } 
    
    # Activity centers of following years. (t=2, 3, ...)
    for (t in 2:n.years) {
      
        # The detected individuals
        for (i in 1:n.detected) {
            sxy[i, 1:2, t] ~ dbinomMNormSourcePPSingle( # Function defined in pointProcess 3.3
              lowerHabCoords[1:numHabWindows, 1:2], 
              upperHabCoords[1:numHabWindows, 1:2], 
              sxy[i, 1:2, t - 1], # depends on last activity center.
              dispSigma, 
              mu[1:numHabWindows], 
              1, 
              numHabWindows, 
              -1)
        }
      
       # The non detected individuals
       for (i in n.detected1:n.individuals) { # i in 1275:2293 
          # n.detected1 = n.detected + 1 (?...)
            sxy[i, 1:2, t] ~ dbinomPPSingle(
              lowerHabCoords[1:numHabWindows, 1:2], 
              upperHabCoords[1:numHabWindows, 1:2], 
              mu[1:numHabWindows], 
              1, 
              numHabWindows)
        }
      
    }
    
    # 
    omeg1[1:3] ~ nimble::ddirch(alpha[1:3])
    
    # State transitions
    for (t in 1:n.years1) { # t in 1:6
        gamma[t] ~ dunif(0, 1)
        w[t] ~ dunif(0, 0.59)
        h[t] ~ dunif(0, 0.39)
        phi[t] <- 1 - h[t] - w[t]
        omega[1, 1, t] <- 1 - gamma[t]
        omega[1, 2, t] <- gamma[t]
        omega[1, 3, t] <- 0
        omega[1, 4, t] <- 0
        omega[2, 1, t] <- 0
        omega[2, 2, t] <- phi[t]
        omega[2, 3, t] <- h[t]
        omega[2, 4, t] <- w[t]
        omega[3, 1, t] <- 0
        omega[3, 2, t] <- 0
        omega[3, 3, t] <- 0
        omega[3, 4, t] <- 1
        omega[4, 1, t] <- 0
        omega[4, 2, t] <- 0
        omega[4, 3, t] <- 0
        omega[4, 4, t] <- 1
    }
    
    # proba to be alive  
    for (i in 1:n.individuals) { # i in 1:2293
        z[i, 1] ~ dcat(omeg1[1:3]) # At time 1
        for (t in 1:n.years1) {
            z[i, t + 1] ~ dcat(omega[z[i, t], 1:4, t]) # At times t= 2, 3, ... 
        }
    }
    
    sigma ~ dunif(0, 4) # width of detection distribution
    
    for (c in 1:n.covs) {
        betaCovs[c] ~ dunif(-5, 5) # jsp
    }
    
    betaResponse ~ dunif(-5, 5)
    
    for (c in 1:n.countries) { # 8 countries
        for (t in 1:n.years) { # t in 1:7
            p0[c, t] ~ dunif(0, 1) # baseline detection probability
        }
    }
    
    for (t in 1:n.years) {
        
        # for all individuals
        for (i in 1:n.individuals) {
            
          # likelihood of a given individual & spatial binary detection history y[i,1:n.detectors]
            y.alive[i, 1:nMaxDetectors, t] ~ dbin_LESS_Cached_MultipleCovResponse( 
              # function in file under the same name
              sxy = sxy[i, 1:2, t], 
              sigma = sigma, 
              nbDetections[i, t], 
              yDets = yDets[i, 1:nMaxDetectors, t], 
              detector.xy = detector.xy[1:n.detectors, 1:2], 
              trials = trials[1:n.detectors], 
              detectorIndex = detectorIndex[1:n.cellsSparse, 
                                            1:maxNBDets], 
              nDetectorsLESS = nDetectorsLESS[1:n.cellsSparse], 
              ResizeFactor = ResizeFactor, 
              maxNBDets = maxNBDets, 
              habitatID = habitatIDDet[1:y.maxDet, 1:x.maxDet], 
              indicator = isAlive[i, t], 
              p0[1:n.countries, t], 
              detCountries[1:n.detectors], 
              detCov = detCovs[1:n.detectors, t, 1:n.covs], 
              betaCov = betaCovs[1:n.covs], 
              BetaResponse = betaResponse, 
              detResponse = detResponse[i, t]
              )
          
            y.dead[i, t] ~ dbern(z[i, t] == 3) # Bernoulli distribution
        }
    }
    for (i in 1:n.individuals) {
        isAlive[i, 1] <- (z[i, 1] == 2)
        for (t in 1:n.years1) {
            isAlive[i, t + 1] <- (z[i, t + 1] == 2)
        }
    }
    for (t in 1:n.years) {
        N[t] <- sum(isAlive[1:n.individuals, t])
    }
}
```

Les parametres du modÃ¨le sont:
```{r}
nimParams
```


## pointProcess 2.3 : dbinomPPSingle 

```{r}
dbinomPPSingle <- nimbleFunction(
	run = function(
		x = double(1),                               # Coordinate values to calculate the density
		lowerCoords = double(2),                     # The lower coordinate values of the observation windows
		upperCoords = double(2),                     # The upper coordinate values of the observation windows
		intensityWeights = double(1, default = 1),   # Values used in the intensity surface (by default a homogeous process is produced)
		areAreas = double(0, default = 1),           # Flag denoting whether the lower and upper coordinates are areas or transects
		numWindows = double(0, default = -1),        # Number of observation windows (if negative the number of rows in lowerCoords is used to define this value)
		log = integer(0, default = 0)                # If not 0 then return the log density
	) {
		## 2.3.1. Specify the return type dimensionality ----
		returnType(double(0))
		## 2.3.2. Create a temporary input matrix ----
		temporaryInput <- matrix(x, ncol = length(x), nrow = 1)
		## 2.3.3. Call the matrix-version of dbinomPP ----
		return(dbinomPP(temporaryInput, 1, lowerCoords, upperCoords, intensityWeights, areAreas, numWindows, log)) # SEE dbinomPP
	}
)
```

## pointProcess 2.1. dbinomPP

```{r}
# Define a function for the density function for the (in)homogenous binomial process
dbinomPP <- nimbleFunction(
   run = function(
      x = double(2),                               # Coordinate values to calculate the density
      numPoints = double(0),                       # The number of points in the binomial process
      lowerCoords = double(2),                     # The lower coordinate values of the observation windows
      upperCoords = double(2),                     # The upper coordinate values of the observation windows
      intensityWeights = double(1, default = 1),   # Values used in the intensity surface (by default a homogeous process is produced)
      areAreas = double(0, default = 1),           # Flag denoting whether the lower and upper coordinates are areas or transects
      numWindows = double(0, default = -1),        # Number of observation windows (if negative the number of rows in lowerCoords is used to define this value)
      log = integer(0, default = 0)                # If not 0 then return the log density
   ) {
     
     
     ###  ~~~~ VALIDATION ~~~~
      # Maximum allowable tolerance for testing to see if points fall on lines (only used when areAreas = 0)
      tolDist <- 6.661338e-16 # Tolerance distance
      
      ## 2.1.1. Specify the return type dimensionality ----
      # Return type declaration
      returnType(double(0))
      
      ## 2.1.2. Sanity test the inputs ----
      # Assess the dimensionality of the input coordinates
      dimCoords <- dim(x)[2]
      # Ensure that the dimensionality is valid
      if(dimCoords <= 0) {
         stop("invalid dimension structure for the input coordinates")
      }
      # Ensure that the number of points corresponds to the dimensionality of the input coordinates
      if(dim(x)[1] < numPoints) {
         # If the number of rows in the output is less than the number of points simulated by the
         # binomial process: return a zero likelihood.  This is often not required as in nearly every
         # application of the binomial process these values will be the same but we need to handle the
         # occasional exception
         if(log) { # Ie if log != 0
            return(-Inf)
         } else { # if log == 0
            return(0.0)
         }
      }
      if(numPoints == 0) {
         # If no points are simulated then the output is certain
         if(log) {
            return(0.0)
         } else {
            return(1.0)
         }
      } else if(numPoints < 0) {
         # Invalid number of points: set likelihood to zero
         if(log) {
            return(-Inf)
         } else {
            return(0.0)
         }
      }
      
      # Assess the number of observation windows
      numObsWindows <- trunc(numWindows)
      if(numObsWindows <= 0) {
         numObsWindows <- dim(lowerCoords)[1]
      }
      # Ensure that the number of observation windows is valid
      if(numObsWindows <= 0) {
         stop("invalid number of observation windows")
      }
      # Check that the number of observation windows is consistent (lower coordinates)
      if(numObsWindows > dim(lowerCoords)[1]) {
         stop("number of observation windows not consistent between lower and upper coordinates (or the 'number of windows' parameter)")
      }
      # Check that the number of observation windows is consistent (upper coordinates)
      if(numObsWindows > dim(upperCoords)[1]) {
         stop("number of observation windows not consistent between lower and upper coordinates (or the 'number of windows' parameter)")
      }
      if(dim(lowerCoords)[2] != dimCoords | dim(upperCoords)[2] != dimCoords) {
         stop("lower and/or upper coordinates have an incorrect dimension structure")
      }
      
      
      ### ~~~~ Calculates observation windows & intensities ~~~~
      # Calculate the area/length of the observation windows
      obsWindowSize <- calcObsWindowSize(
         matrix(lowerCoords[1:numObsWindows, 1:dimCoords], nrow = numObsWindows, ncol = dimCoords),
         matrix(upperCoords[1:numObsWindows, 1:dimCoords], nrow = numObsWindows, ncol = dimCoords),
         areAreas)
      # Recycle the intensity weights to match the number of observation windows
      recIntensityWeights <- numeric(length = numObsWindows, value = intensityWeights, recycle = TRUE)
      # Ensure that the intensity weights are valid
      if(sum(recIntensityWeights < 0.0) > 0) {
         # Invalid values for the intensity weights: set likelihood to zero
         if(log) {
            return(-Inf)
         } else {
            return(0.0)
         }
      }
      # Find the sum of the product of the intensity weights and area
      sumIntensity <- sum(recIntensityWeights * obsWindowSize)
      if(sumIntensity <= 0.0) {
         # Invalid values for the intensity weights: set likelihood to zero
         if(log) {
            return(-Inf)
         } else {
            return(0.0)
         }
      }
      
      
      ## 2.1.3. Calculate the likelihood of each point ----
      logPointDens <- rep(0.0, numPoints)
      for(pointIter in 1:numPoints) {
         curCoords <- x[pointIter, 1:dimCoords]
         # Retrieve the observation windows which the point falls within
         isInObsWindow <- isWithinWindow(curCoords,
            matrix(lowerCoords[1:numObsWindows, 1:dimCoords], nrow = numObsWindows, ncol = dimCoords),
            matrix(upperCoords[1:numObsWindows, 1:dimCoords], nrow = numObsWindows, ncol = dimCoords),
            tolDist, areAreas)
         # Calculate the sum of the intensity
         pointSumIntensity <- sum(isInObsWindow * recIntensityWeights)
         if(pointSumIntensity <= 0.0) {
            if(log) {
               # Return the log scale density if requested
               return(-Inf)
            } else {
               # Return the natural scale density if requested
               return(0.0)
            }
         }
         logPointDens[pointIter] <- log(pointSumIntensity)
      }
      
      ### ~~~~ FINAL CALCULATIONS ~~~~
      ## 2.1.4. Return the retrieved density ----
      outProb <- sum(logPointDens) - numPoints * log(sumIntensity)
      if(log == 0) {
         # Export the output probability on the natural scale if requested
         outProb <- exp(outProb)
      }
      return(outProb)
   }
)
```


